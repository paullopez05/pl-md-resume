{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Previous} Previous\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Code} Code\n */\nimport { ok as assert } from 'uvu/assert';\nimport { asciiAlpha, asciiAlphanumeric, asciiControl, asciiDigit, markdownLineEndingOrSpace, markdownLineEnding, unicodePunctuation, unicodeWhitespace } from 'micromark-util-character';\nimport { codes } from 'micromark-util-symbol/codes.js';\nconst www = {\n  tokenize: tokenizeWww,\n  partial: true\n};\nconst domain = {\n  tokenize: tokenizeDomain,\n  partial: true\n};\nconst path = {\n  tokenize: tokenizePath,\n  partial: true\n};\nconst punctuation = {\n  tokenize: tokenizePunctuation,\n  partial: true\n};\nconst namedCharacterReference = {\n  tokenize: tokenizeNamedCharacterReference,\n  partial: true\n};\nconst wwwAutolink = {\n  tokenize: tokenizeWwwAutolink,\n  previous: previousWww\n};\nconst httpAutolink = {\n  tokenize: tokenizeHttpAutolink,\n  previous: previousHttp\n};\nconst emailAutolink = {\n  tokenize: tokenizeEmailAutolink,\n  previous: previousEmail\n};\n/** @type {ConstructRecord} */\n\nconst text = {};\n/** @type {Extension} */\n\nexport const gfmAutolinkLiteral = {\n  text\n};\nlet code = codes.digit0; // Add alphanumerics.\n\nwhile (code < codes.leftCurlyBrace) {\n  text[code] = emailAutolink;\n  code++;\n  if (code === codes.colon) code = codes.uppercaseA;else if (code === codes.leftSquareBracket) code = codes.lowercaseA;\n}\n\ntext[codes.plusSign] = emailAutolink;\ntext[codes.dash] = emailAutolink;\ntext[codes.dot] = emailAutolink;\ntext[codes.underscore] = emailAutolink;\ntext[codes.uppercaseH] = [emailAutolink, httpAutolink];\ntext[codes.lowercaseH] = [emailAutolink, httpAutolink];\ntext[codes.uppercaseW] = [emailAutolink, wwwAutolink];\ntext[codes.lowercaseW] = [emailAutolink, wwwAutolink];\n/** @type {Tokenizer} */\n\nfunction tokenizeEmailAutolink(effects, ok, nok) {\n  const self = this;\n  /** @type {boolean} */\n\n  let hasDot;\n  /** @type {boolean|undefined} */\n\n  let hasDigitInLastSegment;\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    if (!gfmAtext(code) || !previousEmail(self.previous) || previousUnbalanced(self.events)) {\n      return nok(code);\n    }\n\n    effects.enter('literalAutolink');\n    effects.enter('literalAutolinkEmail');\n    return atext(code);\n  }\n  /** @type {State} */\n\n\n  function atext(code) {\n    if (gfmAtext(code)) {\n      effects.consume(code);\n      return atext;\n    }\n\n    if (code === codes.atSign) {\n      effects.consume(code);\n      return label;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function label(code) {\n    if (code === codes.dot) {\n      return effects.check(punctuation, done, dotContinuation)(code);\n    }\n\n    if (code === codes.dash || code === codes.underscore) {\n      return effects.check(punctuation, nok, dashOrUnderscoreContinuation)(code);\n    }\n\n    if (asciiAlphanumeric(code)) {\n      if (!hasDigitInLastSegment && asciiDigit(code)) {\n        hasDigitInLastSegment = true;\n      }\n\n      effects.consume(code);\n      return label;\n    }\n\n    return done(code);\n  }\n  /** @type {State} */\n\n\n  function dotContinuation(code) {\n    effects.consume(code);\n    hasDot = true;\n    hasDigitInLastSegment = undefined;\n    return label;\n  }\n  /** @type {State} */\n\n\n  function dashOrUnderscoreContinuation(code) {\n    effects.consume(code);\n    return afterDashOrUnderscore;\n  }\n  /** @type {State} */\n\n\n  function afterDashOrUnderscore(code) {\n    if (code === codes.dot) {\n      return effects.check(punctuation, nok, dotContinuation)(code);\n    }\n\n    return label(code);\n  }\n  /** @type {State} */\n\n\n  function done(code) {\n    if (hasDot && !hasDigitInLastSegment) {\n      effects.exit('literalAutolinkEmail');\n      effects.exit('literalAutolink');\n      return ok(code);\n    }\n\n    return nok(code);\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeWwwAutolink(effects, ok, nok) {\n  const self = this;\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    if (code !== codes.uppercaseW && code !== codes.lowercaseW || !previousWww(self.previous) || previousUnbalanced(self.events)) {\n      return nok(code);\n    }\n\n    effects.enter('literalAutolink');\n    effects.enter('literalAutolinkWww'); // For `www.` we check instead of attempt, because when it matches, GH\n    // treats it as part of a domain (yes, it says a valid domain must come\n    // after `www.`, but that’s not how it’s implemented by them).\n\n    return effects.check(www, effects.attempt(domain, effects.attempt(path, done), nok), nok)(code);\n  }\n  /** @type {State} */\n\n\n  function done(code) {\n    effects.exit('literalAutolinkWww');\n    effects.exit('literalAutolink');\n    return ok(code);\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeHttpAutolink(effects, ok, nok) {\n  const self = this;\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    if (code !== codes.uppercaseH && code !== codes.lowercaseH || !previousHttp(self.previous) || previousUnbalanced(self.events)) {\n      return nok(code);\n    }\n\n    effects.enter('literalAutolink');\n    effects.enter('literalAutolinkHttp');\n    effects.consume(code);\n    return t1;\n  }\n  /** @type {State} */\n\n\n  function t1(code) {\n    if (code === codes.uppercaseT || code === codes.lowercaseT) {\n      effects.consume(code);\n      return t2;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function t2(code) {\n    if (code === codes.uppercaseT || code === codes.lowercaseT) {\n      effects.consume(code);\n      return p;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function p(code) {\n    if (code === codes.uppercaseP || code === codes.lowercaseP) {\n      effects.consume(code);\n      return s;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function s(code) {\n    if (code === codes.uppercaseS || code === codes.lowercaseS) {\n      effects.consume(code);\n      return colon;\n    }\n\n    return colon(code);\n  }\n  /** @type {State} */\n\n\n  function colon(code) {\n    if (code === codes.colon) {\n      effects.consume(code);\n      return slash1;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function slash1(code) {\n    if (code === codes.slash) {\n      effects.consume(code);\n      return slash2;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function slash2(code) {\n    if (code === codes.slash) {\n      effects.consume(code);\n      return after;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function after(code) {\n    return code === codes.eof || asciiControl(code) || unicodeWhitespace(code) || unicodePunctuation(code) ? nok(code) : effects.attempt(domain, effects.attempt(path, done), nok)(code);\n  }\n  /** @type {State} */\n\n\n  function done(code) {\n    effects.exit('literalAutolinkHttp');\n    effects.exit('literalAutolink');\n    return ok(code);\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeWww(effects, ok, nok) {\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    assert(code === codes.uppercaseW || code === codes.lowercaseW, 'expected `w`');\n    effects.consume(code);\n    return w2;\n  }\n  /** @type {State} */\n\n\n  function w2(code) {\n    if (code === codes.uppercaseW || code === codes.lowercaseW) {\n      effects.consume(code);\n      return w3;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function w3(code) {\n    if (code === codes.uppercaseW || code === codes.lowercaseW) {\n      effects.consume(code);\n      return dot;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function dot(code) {\n    if (code === codes.dot) {\n      effects.consume(code);\n      return after;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function after(code) {\n    return code === codes.eof || markdownLineEnding(code) ? nok(code) : ok(code);\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeDomain(effects, ok, nok) {\n  /** @type {boolean|undefined} */\n  let hasUnderscoreInLastSegment;\n  /** @type {boolean|undefined} */\n\n  let hasUnderscoreInLastLastSegment;\n  return domain;\n  /** @type {State} */\n\n  function domain(code) {\n    if (code === codes.ampersand) {\n      return effects.check(namedCharacterReference, done, punctuationContinuation)(code);\n    }\n\n    if (code === codes.dot || code === codes.underscore) {\n      return effects.check(punctuation, done, punctuationContinuation)(code);\n    } // GH documents that only alphanumerics (other than `-`, `.`, and `_`) can\n    // occur, which sounds like ASCII only, but they also support `www.點看.com`,\n    // so that’s Unicode.\n    // Instead of some new production for Unicode alphanumerics, markdown\n    // already has that for Unicode punctuation and whitespace, so use those.\n\n\n    if (code === codes.eof || asciiControl(code) || unicodeWhitespace(code) || code !== codes.dash && unicodePunctuation(code)) {\n      return done(code);\n    }\n\n    effects.consume(code);\n    return domain;\n  }\n  /** @type {State} */\n\n\n  function punctuationContinuation(code) {\n    if (code === codes.dot) {\n      hasUnderscoreInLastLastSegment = hasUnderscoreInLastSegment;\n      hasUnderscoreInLastSegment = undefined;\n      effects.consume(code);\n      return domain;\n    }\n\n    if (code === codes.underscore) hasUnderscoreInLastSegment = true;\n    effects.consume(code);\n    return domain;\n  }\n  /** @type {State} */\n\n\n  function done(code) {\n    if (!hasUnderscoreInLastLastSegment && !hasUnderscoreInLastSegment) {\n      return ok(code);\n    }\n\n    return nok(code);\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizePath(effects, ok) {\n  let balance = 0;\n  return inPath;\n  /** @type {State} */\n\n  function inPath(code) {\n    if (code === codes.ampersand) {\n      return effects.check(namedCharacterReference, ok, continuedPunctuation)(code);\n    }\n\n    if (code === codes.leftParenthesis) {\n      balance++;\n    }\n\n    if (code === codes.rightParenthesis) {\n      return effects.check(punctuation, parenAtPathEnd, continuedPunctuation)(code);\n    }\n\n    if (pathEnd(code)) {\n      return ok(code);\n    }\n\n    if (trailingPunctuation(code)) {\n      return effects.check(punctuation, ok, continuedPunctuation)(code);\n    }\n\n    effects.consume(code);\n    return inPath;\n  }\n  /** @type {State} */\n\n\n  function continuedPunctuation(code) {\n    effects.consume(code);\n    return inPath;\n  }\n  /** @type {State} */\n\n\n  function parenAtPathEnd(code) {\n    balance--;\n    return balance < 0 ? ok(code) : continuedPunctuation(code);\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeNamedCharacterReference(effects, ok, nok) {\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    assert(code === codes.ampersand, 'expected `&`');\n    effects.consume(code);\n    return inside;\n  }\n  /** @type {State} */\n\n\n  function inside(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      return inside;\n    }\n\n    if (code === codes.semicolon) {\n      effects.consume(code);\n      return after;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function after(code) {\n    // If the named character reference is followed by the end of the path, it’s\n    // not continued punctuation.\n    return pathEnd(code) ? ok(code) : nok(code);\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizePunctuation(effects, ok, nok) {\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    assert(code === codes.dash || trailingPunctuation(code), 'expected punctuation');\n    effects.consume(code);\n    return after;\n  }\n  /** @type {State} */\n\n\n  function after(code) {\n    // Check the next.\n    if (trailingPunctuation(code)) {\n      effects.consume(code);\n      return after;\n    } // If the punctuation marker is followed by the end of the path, it’s not\n    // continued punctuation.\n\n\n    return pathEnd(code) ? ok(code) : nok(code);\n  }\n}\n/**\n * @param {Code} code\n * @returns {boolean}\n */\n\n\nfunction trailingPunctuation(code) {\n  return code === codes.exclamationMark || code === codes.quotationMark || code === codes.apostrophe || code === codes.rightParenthesis || code === codes.asterisk || code === codes.comma || code === codes.dot || code === codes.colon || code === codes.semicolon || code === codes.lessThan || code === codes.questionMark || code === codes.underscore || code === codes.tilde;\n}\n/**\n * @param {Code} code\n * @returns {boolean}\n */\n\n\nfunction pathEnd(code) {\n  return code === codes.eof || code === codes.lessThan || markdownLineEndingOrSpace(code);\n}\n/**\n * @param {Code} code\n * @returns {boolean}\n */\n\n\nfunction gfmAtext(code) {\n  return code === codes.plusSign || code === codes.dash || code === codes.dot || code === codes.underscore || asciiAlphanumeric(code);\n}\n/** @type {Previous} */\n\n\nfunction previousWww(code) {\n  return code === codes.eof || code === codes.leftParenthesis || code === codes.asterisk || code === codes.underscore || code === codes.tilde || markdownLineEndingOrSpace(code);\n}\n/** @type {Previous} */\n\n\nfunction previousHttp(code) {\n  return code === codes.eof || !asciiAlpha(code);\n}\n/** @type {Previous} */\n\n\nfunction previousEmail(code) {\n  return code !== codes.slash && previousHttp(code);\n}\n/**\n * @param {Array<Event>} events\n * @returns {boolean}\n */\n\n\nfunction previousUnbalanced(events) {\n  let index = events.length;\n  let result = false;\n\n  while (index--) {\n    const token = events[index][1];\n\n    if ((token.type === 'labelLink' || token.type === 'labelImage') && !token._balanced) {\n      result = true;\n      break;\n    } // @ts-expect-error If we’ve seen this token, and it was marked as not\n    // having any unbalanced bracket before it, we can exit.\n\n\n    if (token._gfmAutolinkLiteralWalkedInto) {\n      result = false;\n      break;\n    }\n  }\n\n  if (events.length > 0 && !result) {\n    // @ts-expect-error Mark the last token as “walked into” w/o finding\n    // anything.\n    events[events.length - 1][1]._gfmAutolinkLiteralWalkedInto = true;\n  }\n\n  return result;\n}","map":{"version":3,"sources":["/home/mash/Documents/Code/JavaScript/pl-md-resume/node_modules/micromark-extension-gfm-autolink-literal/dev/lib/syntax.js"],"names":["ok","assert","asciiAlpha","asciiAlphanumeric","asciiControl","asciiDigit","markdownLineEndingOrSpace","markdownLineEnding","unicodePunctuation","unicodeWhitespace","codes","www","tokenize","tokenizeWww","partial","domain","tokenizeDomain","path","tokenizePath","punctuation","tokenizePunctuation","namedCharacterReference","tokenizeNamedCharacterReference","wwwAutolink","tokenizeWwwAutolink","previous","previousWww","httpAutolink","tokenizeHttpAutolink","previousHttp","emailAutolink","tokenizeEmailAutolink","previousEmail","text","gfmAutolinkLiteral","code","digit0","leftCurlyBrace","colon","uppercaseA","leftSquareBracket","lowercaseA","plusSign","dash","dot","underscore","uppercaseH","lowercaseH","uppercaseW","lowercaseW","effects","nok","self","hasDot","hasDigitInLastSegment","start","gfmAtext","previousUnbalanced","events","enter","atext","consume","atSign","label","check","done","dotContinuation","dashOrUnderscoreContinuation","undefined","afterDashOrUnderscore","exit","attempt","t1","uppercaseT","lowercaseT","t2","p","uppercaseP","lowercaseP","s","uppercaseS","lowercaseS","slash1","slash","slash2","after","eof","w2","w3","hasUnderscoreInLastSegment","hasUnderscoreInLastLastSegment","ampersand","punctuationContinuation","balance","inPath","continuedPunctuation","leftParenthesis","rightParenthesis","parenAtPathEnd","pathEnd","trailingPunctuation","inside","semicolon","exclamationMark","quotationMark","apostrophe","asterisk","comma","lessThan","questionMark","tilde","index","length","result","token","type","_balanced","_gfmAutolinkLiteralWalkedInto"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAAQA,EAAE,IAAIC,MAAd,QAA2B,YAA3B;AACA,SACEC,UADF,EAEEC,iBAFF,EAGEC,YAHF,EAIEC,UAJF,EAKEC,yBALF,EAMEC,kBANF,EAOEC,kBAPF,EAQEC,iBARF,QASO,0BATP;AAUA,SAAQC,KAAR,QAAoB,gCAApB;AAEA,MAAMC,GAAG,GAAG;AAACC,EAAAA,QAAQ,EAAEC,WAAX;AAAwBC,EAAAA,OAAO,EAAE;AAAjC,CAAZ;AACA,MAAMC,MAAM,GAAG;AAACH,EAAAA,QAAQ,EAAEI,cAAX;AAA2BF,EAAAA,OAAO,EAAE;AAApC,CAAf;AACA,MAAMG,IAAI,GAAG;AAACL,EAAAA,QAAQ,EAAEM,YAAX;AAAyBJ,EAAAA,OAAO,EAAE;AAAlC,CAAb;AACA,MAAMK,WAAW,GAAG;AAACP,EAAAA,QAAQ,EAAEQ,mBAAX;AAAgCN,EAAAA,OAAO,EAAE;AAAzC,CAApB;AACA,MAAMO,uBAAuB,GAAG;AAC9BT,EAAAA,QAAQ,EAAEU,+BADoB;AAE9BR,EAAAA,OAAO,EAAE;AAFqB,CAAhC;AAKA,MAAMS,WAAW,GAAG;AAACX,EAAAA,QAAQ,EAAEY,mBAAX;AAAgCC,EAAAA,QAAQ,EAAEC;AAA1C,CAApB;AACA,MAAMC,YAAY,GAAG;AAACf,EAAAA,QAAQ,EAAEgB,oBAAX;AAAiCH,EAAAA,QAAQ,EAAEI;AAA3C,CAArB;AACA,MAAMC,aAAa,GAAG;AAAClB,EAAAA,QAAQ,EAAEmB,qBAAX;AAAkCN,EAAAA,QAAQ,EAAEO;AAA5C,CAAtB;AAEA;;AACA,MAAMC,IAAI,GAAG,EAAb;AAEA;;AACA,OAAO,MAAMC,kBAAkB,GAAG;AAACD,EAAAA;AAAD,CAA3B;AAEP,IAAIE,IAAI,GAAGzB,KAAK,CAAC0B,MAAjB,C,CAEA;;AACA,OAAOD,IAAI,GAAGzB,KAAK,CAAC2B,cAApB,EAAoC;AAClCJ,EAAAA,IAAI,CAACE,IAAD,CAAJ,GAAaL,aAAb;AACAK,EAAAA,IAAI;AACJ,MAAIA,IAAI,KAAKzB,KAAK,CAAC4B,KAAnB,EAA0BH,IAAI,GAAGzB,KAAK,CAAC6B,UAAb,CAA1B,KACK,IAAIJ,IAAI,KAAKzB,KAAK,CAAC8B,iBAAnB,EAAsCL,IAAI,GAAGzB,KAAK,CAAC+B,UAAb;AAC5C;;AAEDR,IAAI,CAACvB,KAAK,CAACgC,QAAP,CAAJ,GAAuBZ,aAAvB;AACAG,IAAI,CAACvB,KAAK,CAACiC,IAAP,CAAJ,GAAmBb,aAAnB;AACAG,IAAI,CAACvB,KAAK,CAACkC,GAAP,CAAJ,GAAkBd,aAAlB;AACAG,IAAI,CAACvB,KAAK,CAACmC,UAAP,CAAJ,GAAyBf,aAAzB;AACAG,IAAI,CAACvB,KAAK,CAACoC,UAAP,CAAJ,GAAyB,CAAChB,aAAD,EAAgBH,YAAhB,CAAzB;AACAM,IAAI,CAACvB,KAAK,CAACqC,UAAP,CAAJ,GAAyB,CAACjB,aAAD,EAAgBH,YAAhB,CAAzB;AACAM,IAAI,CAACvB,KAAK,CAACsC,UAAP,CAAJ,GAAyB,CAAClB,aAAD,EAAgBP,WAAhB,CAAzB;AACAU,IAAI,CAACvB,KAAK,CAACuC,UAAP,CAAJ,GAAyB,CAACnB,aAAD,EAAgBP,WAAhB,CAAzB;AAEA;;AACA,SAASQ,qBAAT,CAA+BmB,OAA/B,EAAwClD,EAAxC,EAA4CmD,GAA5C,EAAiD;AAC/C,QAAMC,IAAI,GAAG,IAAb;AACA;;AACA,MAAIC,MAAJ;AACA;;AACA,MAAIC,qBAAJ;AAEA,SAAOC,KAAP;AAEA;;AACA,WAASA,KAAT,CAAepB,IAAf,EAAqB;AACnB,QACE,CAACqB,QAAQ,CAACrB,IAAD,CAAT,IACA,CAACH,aAAa,CAACoB,IAAI,CAAC3B,QAAN,CADd,IAEAgC,kBAAkB,CAACL,IAAI,CAACM,MAAN,CAHpB,EAIE;AACA,aAAOP,GAAG,CAAChB,IAAD,CAAV;AACD;;AAEDe,IAAAA,OAAO,CAACS,KAAR,CAAc,iBAAd;AACAT,IAAAA,OAAO,CAACS,KAAR,CAAc,sBAAd;AACA,WAAOC,KAAK,CAACzB,IAAD,CAAZ;AACD;AAED;;;AACA,WAASyB,KAAT,CAAezB,IAAf,EAAqB;AACnB,QAAIqB,QAAQ,CAACrB,IAAD,CAAZ,EAAoB;AAClBe,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOyB,KAAP;AACD;;AAED,QAAIzB,IAAI,KAAKzB,KAAK,CAACoD,MAAnB,EAA2B;AACzBZ,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAO4B,KAAP;AACD;;AAED,WAAOZ,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAAS4B,KAAT,CAAe5B,IAAf,EAAqB;AACnB,QAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAnB,EAAwB;AACtB,aAAOM,OAAO,CAACc,KAAR,CAAc7C,WAAd,EAA2B8C,IAA3B,EAAiCC,eAAjC,EAAkD/B,IAAlD,CAAP;AACD;;AAED,QAAIA,IAAI,KAAKzB,KAAK,CAACiC,IAAf,IAAuBR,IAAI,KAAKzB,KAAK,CAACmC,UAA1C,EAAsD;AACpD,aAAOK,OAAO,CAACc,KAAR,CAAc7C,WAAd,EAA2BgC,GAA3B,EAAgCgB,4BAAhC,EAA8DhC,IAA9D,CAAP;AACD;;AAED,QAAIhC,iBAAiB,CAACgC,IAAD,CAArB,EAA6B;AAC3B,UAAI,CAACmB,qBAAD,IAA0BjD,UAAU,CAAC8B,IAAD,CAAxC,EAAgD;AAC9CmB,QAAAA,qBAAqB,GAAG,IAAxB;AACD;;AAEDJ,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAO4B,KAAP;AACD;;AAED,WAAOE,IAAI,CAAC9B,IAAD,CAAX;AACD;AAED;;;AACA,WAAS+B,eAAT,CAAyB/B,IAAzB,EAA+B;AAC7Be,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACAkB,IAAAA,MAAM,GAAG,IAAT;AACAC,IAAAA,qBAAqB,GAAGc,SAAxB;AACA,WAAOL,KAAP;AACD;AAED;;;AACA,WAASI,4BAAT,CAAsChC,IAAtC,EAA4C;AAC1Ce,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,WAAOkC,qBAAP;AACD;AAED;;;AACA,WAASA,qBAAT,CAA+BlC,IAA/B,EAAqC;AACnC,QAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAnB,EAAwB;AACtB,aAAOM,OAAO,CAACc,KAAR,CAAc7C,WAAd,EAA2BgC,GAA3B,EAAgCe,eAAhC,EAAiD/B,IAAjD,CAAP;AACD;;AAED,WAAO4B,KAAK,CAAC5B,IAAD,CAAZ;AACD;AAED;;;AACA,WAAS8B,IAAT,CAAc9B,IAAd,EAAoB;AAClB,QAAIkB,MAAM,IAAI,CAACC,qBAAf,EAAsC;AACpCJ,MAAAA,OAAO,CAACoB,IAAR,CAAa,sBAAb;AACApB,MAAAA,OAAO,CAACoB,IAAR,CAAa,iBAAb;AACA,aAAOtE,EAAE,CAACmC,IAAD,CAAT;AACD;;AAED,WAAOgB,GAAG,CAAChB,IAAD,CAAV;AACD;AACF;AAED;;;AACA,SAASX,mBAAT,CAA6B0B,OAA7B,EAAsClD,EAAtC,EAA0CmD,GAA1C,EAA+C;AAC7C,QAAMC,IAAI,GAAG,IAAb;AAEA,SAAOG,KAAP;AAEA;;AACA,WAASA,KAAT,CAAepB,IAAf,EAAqB;AACnB,QACGA,IAAI,KAAKzB,KAAK,CAACsC,UAAf,IAA6Bb,IAAI,KAAKzB,KAAK,CAACuC,UAA7C,IACA,CAACvB,WAAW,CAAC0B,IAAI,CAAC3B,QAAN,CADZ,IAEAgC,kBAAkB,CAACL,IAAI,CAACM,MAAN,CAHpB,EAIE;AACA,aAAOP,GAAG,CAAChB,IAAD,CAAV;AACD;;AAEDe,IAAAA,OAAO,CAACS,KAAR,CAAc,iBAAd;AACAT,IAAAA,OAAO,CAACS,KAAR,CAAc,oBAAd,EAVmB,CAWnB;AACA;AACA;;AACA,WAAOT,OAAO,CAACc,KAAR,CACLrD,GADK,EAELuC,OAAO,CAACqB,OAAR,CAAgBxD,MAAhB,EAAwBmC,OAAO,CAACqB,OAAR,CAAgBtD,IAAhB,EAAsBgD,IAAtB,CAAxB,EAAqDd,GAArD,CAFK,EAGLA,GAHK,EAILhB,IAJK,CAAP;AAKD;AAED;;;AACA,WAAS8B,IAAT,CAAc9B,IAAd,EAAoB;AAClBe,IAAAA,OAAO,CAACoB,IAAR,CAAa,oBAAb;AACApB,IAAAA,OAAO,CAACoB,IAAR,CAAa,iBAAb;AACA,WAAOtE,EAAE,CAACmC,IAAD,CAAT;AACD;AACF;AAED;;;AACA,SAASP,oBAAT,CAA8BsB,OAA9B,EAAuClD,EAAvC,EAA2CmD,GAA3C,EAAgD;AAC9C,QAAMC,IAAI,GAAG,IAAb;AAEA,SAAOG,KAAP;AAEA;;AACA,WAASA,KAAT,CAAepB,IAAf,EAAqB;AACnB,QACGA,IAAI,KAAKzB,KAAK,CAACoC,UAAf,IAA6BX,IAAI,KAAKzB,KAAK,CAACqC,UAA7C,IACA,CAAClB,YAAY,CAACuB,IAAI,CAAC3B,QAAN,CADb,IAEAgC,kBAAkB,CAACL,IAAI,CAACM,MAAN,CAHpB,EAIE;AACA,aAAOP,GAAG,CAAChB,IAAD,CAAV;AACD;;AAEDe,IAAAA,OAAO,CAACS,KAAR,CAAc,iBAAd;AACAT,IAAAA,OAAO,CAACS,KAAR,CAAc,qBAAd;AACAT,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,WAAOqC,EAAP;AACD;AAED;;;AACA,WAASA,EAAT,CAAYrC,IAAZ,EAAkB;AAChB,QAAIA,IAAI,KAAKzB,KAAK,CAAC+D,UAAf,IAA6BtC,IAAI,KAAKzB,KAAK,CAACgE,UAAhD,EAA4D;AAC1DxB,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOwC,EAAP;AACD;;AAED,WAAOxB,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAASwC,EAAT,CAAYxC,IAAZ,EAAkB;AAChB,QAAIA,IAAI,KAAKzB,KAAK,CAAC+D,UAAf,IAA6BtC,IAAI,KAAKzB,KAAK,CAACgE,UAAhD,EAA4D;AAC1DxB,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOyC,CAAP;AACD;;AAED,WAAOzB,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAASyC,CAAT,CAAWzC,IAAX,EAAiB;AACf,QAAIA,IAAI,KAAKzB,KAAK,CAACmE,UAAf,IAA6B1C,IAAI,KAAKzB,KAAK,CAACoE,UAAhD,EAA4D;AAC1D5B,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAO4C,CAAP;AACD;;AAED,WAAO5B,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAAS4C,CAAT,CAAW5C,IAAX,EAAiB;AACf,QAAIA,IAAI,KAAKzB,KAAK,CAACsE,UAAf,IAA6B7C,IAAI,KAAKzB,KAAK,CAACuE,UAAhD,EAA4D;AAC1D/B,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOG,KAAP;AACD;;AAED,WAAOA,KAAK,CAACH,IAAD,CAAZ;AACD;AAED;;;AACA,WAASG,KAAT,CAAeH,IAAf,EAAqB;AACnB,QAAIA,IAAI,KAAKzB,KAAK,CAAC4B,KAAnB,EAA0B;AACxBY,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAO+C,MAAP;AACD;;AAED,WAAO/B,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAAS+C,MAAT,CAAgB/C,IAAhB,EAAsB;AACpB,QAAIA,IAAI,KAAKzB,KAAK,CAACyE,KAAnB,EAA0B;AACxBjC,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOiD,MAAP;AACD;;AAED,WAAOjC,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAASiD,MAAT,CAAgBjD,IAAhB,EAAsB;AACpB,QAAIA,IAAI,KAAKzB,KAAK,CAACyE,KAAnB,EAA0B;AACxBjC,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOkD,KAAP;AACD;;AAED,WAAOlC,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAASkD,KAAT,CAAelD,IAAf,EAAqB;AACnB,WAAOA,IAAI,KAAKzB,KAAK,CAAC4E,GAAf,IACLlF,YAAY,CAAC+B,IAAD,CADP,IAEL1B,iBAAiB,CAAC0B,IAAD,CAFZ,IAGL3B,kBAAkB,CAAC2B,IAAD,CAHb,GAIHgB,GAAG,CAAChB,IAAD,CAJA,GAKHe,OAAO,CAACqB,OAAR,CAAgBxD,MAAhB,EAAwBmC,OAAO,CAACqB,OAAR,CAAgBtD,IAAhB,EAAsBgD,IAAtB,CAAxB,EAAqDd,GAArD,EAA0DhB,IAA1D,CALJ;AAMD;AAED;;;AACA,WAAS8B,IAAT,CAAc9B,IAAd,EAAoB;AAClBe,IAAAA,OAAO,CAACoB,IAAR,CAAa,qBAAb;AACApB,IAAAA,OAAO,CAACoB,IAAR,CAAa,iBAAb;AACA,WAAOtE,EAAE,CAACmC,IAAD,CAAT;AACD;AACF;AAED;;;AACA,SAAStB,WAAT,CAAqBqC,OAArB,EAA8BlD,EAA9B,EAAkCmD,GAAlC,EAAuC;AACrC,SAAOI,KAAP;AAEA;;AACA,WAASA,KAAT,CAAepB,IAAf,EAAqB;AACnBlC,IAAAA,MAAM,CACJkC,IAAI,KAAKzB,KAAK,CAACsC,UAAf,IAA6Bb,IAAI,KAAKzB,KAAK,CAACuC,UADxC,EAEJ,cAFI,CAAN;AAIAC,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,WAAOoD,EAAP;AACD;AAED;;;AACA,WAASA,EAAT,CAAYpD,IAAZ,EAAkB;AAChB,QAAIA,IAAI,KAAKzB,KAAK,CAACsC,UAAf,IAA6Bb,IAAI,KAAKzB,KAAK,CAACuC,UAAhD,EAA4D;AAC1DC,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOqD,EAAP;AACD;;AAED,WAAOrC,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAASqD,EAAT,CAAYrD,IAAZ,EAAkB;AAChB,QAAIA,IAAI,KAAKzB,KAAK,CAACsC,UAAf,IAA6Bb,IAAI,KAAKzB,KAAK,CAACuC,UAAhD,EAA4D;AAC1DC,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOS,GAAP;AACD;;AAED,WAAOO,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAASS,GAAT,CAAaT,IAAb,EAAmB;AACjB,QAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAnB,EAAwB;AACtBM,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOkD,KAAP;AACD;;AAED,WAAOlC,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAASkD,KAAT,CAAelD,IAAf,EAAqB;AACnB,WAAOA,IAAI,KAAKzB,KAAK,CAAC4E,GAAf,IAAsB/E,kBAAkB,CAAC4B,IAAD,CAAxC,GAAiDgB,GAAG,CAAChB,IAAD,CAApD,GAA6DnC,EAAE,CAACmC,IAAD,CAAtE;AACD;AACF;AAED;;;AACA,SAASnB,cAAT,CAAwBkC,OAAxB,EAAiClD,EAAjC,EAAqCmD,GAArC,EAA0C;AACxC;AACA,MAAIsC,0BAAJ;AACA;;AACA,MAAIC,8BAAJ;AAEA,SAAO3E,MAAP;AAEA;;AACA,WAASA,MAAT,CAAgBoB,IAAhB,EAAsB;AACpB,QAAIA,IAAI,KAAKzB,KAAK,CAACiF,SAAnB,EAA8B;AAC5B,aAAOzC,OAAO,CAACc,KAAR,CACL3C,uBADK,EAEL4C,IAFK,EAGL2B,uBAHK,EAILzD,IAJK,CAAP;AAKD;;AAED,QAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAf,IAAsBT,IAAI,KAAKzB,KAAK,CAACmC,UAAzC,EAAqD;AACnD,aAAOK,OAAO,CAACc,KAAR,CAAc7C,WAAd,EAA2B8C,IAA3B,EAAiC2B,uBAAjC,EAA0DzD,IAA1D,CAAP;AACD,KAXmB,CAapB;AACA;AACA;AACA;AACA;;;AACA,QACEA,IAAI,KAAKzB,KAAK,CAAC4E,GAAf,IACAlF,YAAY,CAAC+B,IAAD,CADZ,IAEA1B,iBAAiB,CAAC0B,IAAD,CAFjB,IAGCA,IAAI,KAAKzB,KAAK,CAACiC,IAAf,IAAuBnC,kBAAkB,CAAC2B,IAAD,CAJ5C,EAKE;AACA,aAAO8B,IAAI,CAAC9B,IAAD,CAAX;AACD;;AAEDe,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,WAAOpB,MAAP;AACD;AAED;;;AACA,WAAS6E,uBAAT,CAAiCzD,IAAjC,EAAuC;AACrC,QAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAnB,EAAwB;AACtB8C,MAAAA,8BAA8B,GAAGD,0BAAjC;AACAA,MAAAA,0BAA0B,GAAGrB,SAA7B;AACAlB,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOpB,MAAP;AACD;;AAED,QAAIoB,IAAI,KAAKzB,KAAK,CAACmC,UAAnB,EAA+B4C,0BAA0B,GAAG,IAA7B;AAE/BvC,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,WAAOpB,MAAP;AACD;AAED;;;AACA,WAASkD,IAAT,CAAc9B,IAAd,EAAoB;AAClB,QAAI,CAACuD,8BAAD,IAAmC,CAACD,0BAAxC,EAAoE;AAClE,aAAOzF,EAAE,CAACmC,IAAD,CAAT;AACD;;AAED,WAAOgB,GAAG,CAAChB,IAAD,CAAV;AACD;AACF;AAED;;;AACA,SAASjB,YAAT,CAAsBgC,OAAtB,EAA+BlD,EAA/B,EAAmC;AACjC,MAAI6F,OAAO,GAAG,CAAd;AAEA,SAAOC,MAAP;AAEA;;AACA,WAASA,MAAT,CAAgB3D,IAAhB,EAAsB;AACpB,QAAIA,IAAI,KAAKzB,KAAK,CAACiF,SAAnB,EAA8B;AAC5B,aAAOzC,OAAO,CAACc,KAAR,CACL3C,uBADK,EAELrB,EAFK,EAGL+F,oBAHK,EAIL5D,IAJK,CAAP;AAKD;;AAED,QAAIA,IAAI,KAAKzB,KAAK,CAACsF,eAAnB,EAAoC;AAClCH,MAAAA,OAAO;AACR;;AAED,QAAI1D,IAAI,KAAKzB,KAAK,CAACuF,gBAAnB,EAAqC;AACnC,aAAO/C,OAAO,CAACc,KAAR,CACL7C,WADK,EAEL+E,cAFK,EAGLH,oBAHK,EAIL5D,IAJK,CAAP;AAKD;;AAED,QAAIgE,OAAO,CAAChE,IAAD,CAAX,EAAmB;AACjB,aAAOnC,EAAE,CAACmC,IAAD,CAAT;AACD;;AAED,QAAIiE,mBAAmB,CAACjE,IAAD,CAAvB,EAA+B;AAC7B,aAAOe,OAAO,CAACc,KAAR,CAAc7C,WAAd,EAA2BnB,EAA3B,EAA+B+F,oBAA/B,EAAqD5D,IAArD,CAAP;AACD;;AAEDe,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,WAAO2D,MAAP;AACD;AAED;;;AACA,WAASC,oBAAT,CAA8B5D,IAA9B,EAAoC;AAClCe,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,WAAO2D,MAAP;AACD;AAED;;;AACA,WAASI,cAAT,CAAwB/D,IAAxB,EAA8B;AAC5B0D,IAAAA,OAAO;AACP,WAAOA,OAAO,GAAG,CAAV,GAAc7F,EAAE,CAACmC,IAAD,CAAhB,GAAyB4D,oBAAoB,CAAC5D,IAAD,CAApD;AACD;AACF;AAED;;;AACA,SAASb,+BAAT,CAAyC4B,OAAzC,EAAkDlD,EAAlD,EAAsDmD,GAAtD,EAA2D;AACzD,SAAOI,KAAP;AAEA;;AACA,WAASA,KAAT,CAAepB,IAAf,EAAqB;AACnBlC,IAAAA,MAAM,CAACkC,IAAI,KAAKzB,KAAK,CAACiF,SAAhB,EAA2B,cAA3B,CAAN;AACAzC,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,WAAOkE,MAAP;AACD;AAED;;;AACA,WAASA,MAAT,CAAgBlE,IAAhB,EAAsB;AACpB,QAAIjC,UAAU,CAACiC,IAAD,CAAd,EAAsB;AACpBe,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOkE,MAAP;AACD;;AAED,QAAIlE,IAAI,KAAKzB,KAAK,CAAC4F,SAAnB,EAA8B;AAC5BpD,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOkD,KAAP;AACD;;AAED,WAAOlC,GAAG,CAAChB,IAAD,CAAV;AACD;AAED;;;AACA,WAASkD,KAAT,CAAelD,IAAf,EAAqB;AACnB;AACA;AACA,WAAOgE,OAAO,CAAChE,IAAD,CAAP,GAAgBnC,EAAE,CAACmC,IAAD,CAAlB,GAA2BgB,GAAG,CAAChB,IAAD,CAArC;AACD;AACF;AAED;;;AACA,SAASf,mBAAT,CAA6B8B,OAA7B,EAAsClD,EAAtC,EAA0CmD,GAA1C,EAA+C;AAC7C,SAAOI,KAAP;AAEA;;AACA,WAASA,KAAT,CAAepB,IAAf,EAAqB;AACnBlC,IAAAA,MAAM,CACJkC,IAAI,KAAKzB,KAAK,CAACiC,IAAf,IAAuByD,mBAAmB,CAACjE,IAAD,CADtC,EAEJ,sBAFI,CAAN;AAIAe,IAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,WAAOkD,KAAP;AACD;AAED;;;AACA,WAASA,KAAT,CAAelD,IAAf,EAAqB;AACnB;AACA,QAAIiE,mBAAmB,CAACjE,IAAD,CAAvB,EAA+B;AAC7Be,MAAAA,OAAO,CAACW,OAAR,CAAgB1B,IAAhB;AACA,aAAOkD,KAAP;AACD,KALkB,CAOnB;AACA;;;AACA,WAAOc,OAAO,CAAChE,IAAD,CAAP,GAAgBnC,EAAE,CAACmC,IAAD,CAAlB,GAA2BgB,GAAG,CAAChB,IAAD,CAArC;AACD;AACF;AAED;AACA;AACA;AACA;;;AACA,SAASiE,mBAAT,CAA6BjE,IAA7B,EAAmC;AACjC,SACEA,IAAI,KAAKzB,KAAK,CAAC6F,eAAf,IACApE,IAAI,KAAKzB,KAAK,CAAC8F,aADf,IAEArE,IAAI,KAAKzB,KAAK,CAAC+F,UAFf,IAGAtE,IAAI,KAAKzB,KAAK,CAACuF,gBAHf,IAIA9D,IAAI,KAAKzB,KAAK,CAACgG,QAJf,IAKAvE,IAAI,KAAKzB,KAAK,CAACiG,KALf,IAMAxE,IAAI,KAAKzB,KAAK,CAACkC,GANf,IAOAT,IAAI,KAAKzB,KAAK,CAAC4B,KAPf,IAQAH,IAAI,KAAKzB,KAAK,CAAC4F,SARf,IASAnE,IAAI,KAAKzB,KAAK,CAACkG,QATf,IAUAzE,IAAI,KAAKzB,KAAK,CAACmG,YAVf,IAWA1E,IAAI,KAAKzB,KAAK,CAACmC,UAXf,IAYAV,IAAI,KAAKzB,KAAK,CAACoG,KAbjB;AAeD;AAED;AACA;AACA;AACA;;;AACA,SAASX,OAAT,CAAiBhE,IAAjB,EAAuB;AACrB,SACEA,IAAI,KAAKzB,KAAK,CAAC4E,GAAf,IACAnD,IAAI,KAAKzB,KAAK,CAACkG,QADf,IAEAtG,yBAAyB,CAAC6B,IAAD,CAH3B;AAKD;AAED;AACA;AACA;AACA;;;AACA,SAASqB,QAAT,CAAkBrB,IAAlB,EAAwB;AACtB,SACEA,IAAI,KAAKzB,KAAK,CAACgC,QAAf,IACAP,IAAI,KAAKzB,KAAK,CAACiC,IADf,IAEAR,IAAI,KAAKzB,KAAK,CAACkC,GAFf,IAGAT,IAAI,KAAKzB,KAAK,CAACmC,UAHf,IAIA1C,iBAAiB,CAACgC,IAAD,CALnB;AAOD;AAED;;;AACA,SAAST,WAAT,CAAqBS,IAArB,EAA2B;AACzB,SACEA,IAAI,KAAKzB,KAAK,CAAC4E,GAAf,IACAnD,IAAI,KAAKzB,KAAK,CAACsF,eADf,IAEA7D,IAAI,KAAKzB,KAAK,CAACgG,QAFf,IAGAvE,IAAI,KAAKzB,KAAK,CAACmC,UAHf,IAIAV,IAAI,KAAKzB,KAAK,CAACoG,KAJf,IAKAxG,yBAAyB,CAAC6B,IAAD,CAN3B;AAQD;AAED;;;AACA,SAASN,YAAT,CAAsBM,IAAtB,EAA4B;AAC1B,SAAOA,IAAI,KAAKzB,KAAK,CAAC4E,GAAf,IAAsB,CAACpF,UAAU,CAACiC,IAAD,CAAxC;AACD;AAED;;;AACA,SAASH,aAAT,CAAuBG,IAAvB,EAA6B;AAC3B,SAAOA,IAAI,KAAKzB,KAAK,CAACyE,KAAf,IAAwBtD,YAAY,CAACM,IAAD,CAA3C;AACD;AAED;AACA;AACA;AACA;;;AACA,SAASsB,kBAAT,CAA4BC,MAA5B,EAAoC;AAClC,MAAIqD,KAAK,GAAGrD,MAAM,CAACsD,MAAnB;AACA,MAAIC,MAAM,GAAG,KAAb;;AAEA,SAAOF,KAAK,EAAZ,EAAgB;AACd,UAAMG,KAAK,GAAGxD,MAAM,CAACqD,KAAD,CAAN,CAAc,CAAd,CAAd;;AAEA,QACE,CAACG,KAAK,CAACC,IAAN,KAAe,WAAf,IAA8BD,KAAK,CAACC,IAAN,KAAe,YAA9C,KACA,CAACD,KAAK,CAACE,SAFT,EAGE;AACAH,MAAAA,MAAM,GAAG,IAAT;AACA;AACD,KATa,CAWd;AACA;;;AACA,QAAIC,KAAK,CAACG,6BAAV,EAAyC;AACvCJ,MAAAA,MAAM,GAAG,KAAT;AACA;AACD;AACF;;AAED,MAAIvD,MAAM,CAACsD,MAAP,GAAgB,CAAhB,IAAqB,CAACC,MAA1B,EAAkC;AAChC;AACA;AACAvD,IAAAA,MAAM,CAACA,MAAM,CAACsD,MAAP,GAAgB,CAAjB,CAAN,CAA0B,CAA1B,EAA6BK,6BAA7B,GAA6D,IAA7D;AACD;;AAED,SAAOJ,MAAP;AACD","sourcesContent":["/**\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Previous} Previous\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport {ok as assert} from 'uvu/assert'\nimport {\n  asciiAlpha,\n  asciiAlphanumeric,\n  asciiControl,\n  asciiDigit,\n  markdownLineEndingOrSpace,\n  markdownLineEnding,\n  unicodePunctuation,\n  unicodeWhitespace\n} from 'micromark-util-character'\nimport {codes} from 'micromark-util-symbol/codes.js'\n\nconst www = {tokenize: tokenizeWww, partial: true}\nconst domain = {tokenize: tokenizeDomain, partial: true}\nconst path = {tokenize: tokenizePath, partial: true}\nconst punctuation = {tokenize: tokenizePunctuation, partial: true}\nconst namedCharacterReference = {\n  tokenize: tokenizeNamedCharacterReference,\n  partial: true\n}\n\nconst wwwAutolink = {tokenize: tokenizeWwwAutolink, previous: previousWww}\nconst httpAutolink = {tokenize: tokenizeHttpAutolink, previous: previousHttp}\nconst emailAutolink = {tokenize: tokenizeEmailAutolink, previous: previousEmail}\n\n/** @type {ConstructRecord} */\nconst text = {}\n\n/** @type {Extension} */\nexport const gfmAutolinkLiteral = {text}\n\nlet code = codes.digit0\n\n// Add alphanumerics.\nwhile (code < codes.leftCurlyBrace) {\n  text[code] = emailAutolink\n  code++\n  if (code === codes.colon) code = codes.uppercaseA\n  else if (code === codes.leftSquareBracket) code = codes.lowercaseA\n}\n\ntext[codes.plusSign] = emailAutolink\ntext[codes.dash] = emailAutolink\ntext[codes.dot] = emailAutolink\ntext[codes.underscore] = emailAutolink\ntext[codes.uppercaseH] = [emailAutolink, httpAutolink]\ntext[codes.lowercaseH] = [emailAutolink, httpAutolink]\ntext[codes.uppercaseW] = [emailAutolink, wwwAutolink]\ntext[codes.lowercaseW] = [emailAutolink, wwwAutolink]\n\n/** @type {Tokenizer} */\nfunction tokenizeEmailAutolink(effects, ok, nok) {\n  const self = this\n  /** @type {boolean} */\n  let hasDot\n  /** @type {boolean|undefined} */\n  let hasDigitInLastSegment\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    if (\n      !gfmAtext(code) ||\n      !previousEmail(self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkEmail')\n    return atext(code)\n  }\n\n  /** @type {State} */\n  function atext(code) {\n    if (gfmAtext(code)) {\n      effects.consume(code)\n      return atext\n    }\n\n    if (code === codes.atSign) {\n      effects.consume(code)\n      return label\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function label(code) {\n    if (code === codes.dot) {\n      return effects.check(punctuation, done, dotContinuation)(code)\n    }\n\n    if (code === codes.dash || code === codes.underscore) {\n      return effects.check(punctuation, nok, dashOrUnderscoreContinuation)(code)\n    }\n\n    if (asciiAlphanumeric(code)) {\n      if (!hasDigitInLastSegment && asciiDigit(code)) {\n        hasDigitInLastSegment = true\n      }\n\n      effects.consume(code)\n      return label\n    }\n\n    return done(code)\n  }\n\n  /** @type {State} */\n  function dotContinuation(code) {\n    effects.consume(code)\n    hasDot = true\n    hasDigitInLastSegment = undefined\n    return label\n  }\n\n  /** @type {State} */\n  function dashOrUnderscoreContinuation(code) {\n    effects.consume(code)\n    return afterDashOrUnderscore\n  }\n\n  /** @type {State} */\n  function afterDashOrUnderscore(code) {\n    if (code === codes.dot) {\n      return effects.check(punctuation, nok, dotContinuation)(code)\n    }\n\n    return label(code)\n  }\n\n  /** @type {State} */\n  function done(code) {\n    if (hasDot && !hasDigitInLastSegment) {\n      effects.exit('literalAutolinkEmail')\n      effects.exit('literalAutolink')\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeWwwAutolink(effects, ok, nok) {\n  const self = this\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    if (\n      (code !== codes.uppercaseW && code !== codes.lowercaseW) ||\n      !previousWww(self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkWww')\n    // For `www.` we check instead of attempt, because when it matches, GH\n    // treats it as part of a domain (yes, it says a valid domain must come\n    // after `www.`, but that’s not how it’s implemented by them).\n    return effects.check(\n      www,\n      effects.attempt(domain, effects.attempt(path, done), nok),\n      nok\n    )(code)\n  }\n\n  /** @type {State} */\n  function done(code) {\n    effects.exit('literalAutolinkWww')\n    effects.exit('literalAutolink')\n    return ok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeHttpAutolink(effects, ok, nok) {\n  const self = this\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    if (\n      (code !== codes.uppercaseH && code !== codes.lowercaseH) ||\n      !previousHttp(self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkHttp')\n    effects.consume(code)\n    return t1\n  }\n\n  /** @type {State} */\n  function t1(code) {\n    if (code === codes.uppercaseT || code === codes.lowercaseT) {\n      effects.consume(code)\n      return t2\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function t2(code) {\n    if (code === codes.uppercaseT || code === codes.lowercaseT) {\n      effects.consume(code)\n      return p\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function p(code) {\n    if (code === codes.uppercaseP || code === codes.lowercaseP) {\n      effects.consume(code)\n      return s\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function s(code) {\n    if (code === codes.uppercaseS || code === codes.lowercaseS) {\n      effects.consume(code)\n      return colon\n    }\n\n    return colon(code)\n  }\n\n  /** @type {State} */\n  function colon(code) {\n    if (code === codes.colon) {\n      effects.consume(code)\n      return slash1\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function slash1(code) {\n    if (code === codes.slash) {\n      effects.consume(code)\n      return slash2\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function slash2(code) {\n    if (code === codes.slash) {\n      effects.consume(code)\n      return after\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function after(code) {\n    return code === codes.eof ||\n      asciiControl(code) ||\n      unicodeWhitespace(code) ||\n      unicodePunctuation(code)\n      ? nok(code)\n      : effects.attempt(domain, effects.attempt(path, done), nok)(code)\n  }\n\n  /** @type {State} */\n  function done(code) {\n    effects.exit('literalAutolinkHttp')\n    effects.exit('literalAutolink')\n    return ok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeWww(effects, ok, nok) {\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    assert(\n      code === codes.uppercaseW || code === codes.lowercaseW,\n      'expected `w`'\n    )\n    effects.consume(code)\n    return w2\n  }\n\n  /** @type {State} */\n  function w2(code) {\n    if (code === codes.uppercaseW || code === codes.lowercaseW) {\n      effects.consume(code)\n      return w3\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function w3(code) {\n    if (code === codes.uppercaseW || code === codes.lowercaseW) {\n      effects.consume(code)\n      return dot\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function dot(code) {\n    if (code === codes.dot) {\n      effects.consume(code)\n      return after\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function after(code) {\n    return code === codes.eof || markdownLineEnding(code) ? nok(code) : ok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeDomain(effects, ok, nok) {\n  /** @type {boolean|undefined} */\n  let hasUnderscoreInLastSegment\n  /** @type {boolean|undefined} */\n  let hasUnderscoreInLastLastSegment\n\n  return domain\n\n  /** @type {State} */\n  function domain(code) {\n    if (code === codes.ampersand) {\n      return effects.check(\n        namedCharacterReference,\n        done,\n        punctuationContinuation\n      )(code)\n    }\n\n    if (code === codes.dot || code === codes.underscore) {\n      return effects.check(punctuation, done, punctuationContinuation)(code)\n    }\n\n    // GH documents that only alphanumerics (other than `-`, `.`, and `_`) can\n    // occur, which sounds like ASCII only, but they also support `www.點看.com`,\n    // so that’s Unicode.\n    // Instead of some new production for Unicode alphanumerics, markdown\n    // already has that for Unicode punctuation and whitespace, so use those.\n    if (\n      code === codes.eof ||\n      asciiControl(code) ||\n      unicodeWhitespace(code) ||\n      (code !== codes.dash && unicodePunctuation(code))\n    ) {\n      return done(code)\n    }\n\n    effects.consume(code)\n    return domain\n  }\n\n  /** @type {State} */\n  function punctuationContinuation(code) {\n    if (code === codes.dot) {\n      hasUnderscoreInLastLastSegment = hasUnderscoreInLastSegment\n      hasUnderscoreInLastSegment = undefined\n      effects.consume(code)\n      return domain\n    }\n\n    if (code === codes.underscore) hasUnderscoreInLastSegment = true\n\n    effects.consume(code)\n    return domain\n  }\n\n  /** @type {State} */\n  function done(code) {\n    if (!hasUnderscoreInLastLastSegment && !hasUnderscoreInLastSegment) {\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizePath(effects, ok) {\n  let balance = 0\n\n  return inPath\n\n  /** @type {State} */\n  function inPath(code) {\n    if (code === codes.ampersand) {\n      return effects.check(\n        namedCharacterReference,\n        ok,\n        continuedPunctuation\n      )(code)\n    }\n\n    if (code === codes.leftParenthesis) {\n      balance++\n    }\n\n    if (code === codes.rightParenthesis) {\n      return effects.check(\n        punctuation,\n        parenAtPathEnd,\n        continuedPunctuation\n      )(code)\n    }\n\n    if (pathEnd(code)) {\n      return ok(code)\n    }\n\n    if (trailingPunctuation(code)) {\n      return effects.check(punctuation, ok, continuedPunctuation)(code)\n    }\n\n    effects.consume(code)\n    return inPath\n  }\n\n  /** @type {State} */\n  function continuedPunctuation(code) {\n    effects.consume(code)\n    return inPath\n  }\n\n  /** @type {State} */\n  function parenAtPathEnd(code) {\n    balance--\n    return balance < 0 ? ok(code) : continuedPunctuation(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeNamedCharacterReference(effects, ok, nok) {\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    assert(code === codes.ampersand, 'expected `&`')\n    effects.consume(code)\n    return inside\n  }\n\n  /** @type {State} */\n  function inside(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return inside\n    }\n\n    if (code === codes.semicolon) {\n      effects.consume(code)\n      return after\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function after(code) {\n    // If the named character reference is followed by the end of the path, it’s\n    // not continued punctuation.\n    return pathEnd(code) ? ok(code) : nok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizePunctuation(effects, ok, nok) {\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    assert(\n      code === codes.dash || trailingPunctuation(code),\n      'expected punctuation'\n    )\n    effects.consume(code)\n    return after\n  }\n\n  /** @type {State} */\n  function after(code) {\n    // Check the next.\n    if (trailingPunctuation(code)) {\n      effects.consume(code)\n      return after\n    }\n\n    // If the punctuation marker is followed by the end of the path, it’s not\n    // continued punctuation.\n    return pathEnd(code) ? ok(code) : nok(code)\n  }\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction trailingPunctuation(code) {\n  return (\n    code === codes.exclamationMark ||\n    code === codes.quotationMark ||\n    code === codes.apostrophe ||\n    code === codes.rightParenthesis ||\n    code === codes.asterisk ||\n    code === codes.comma ||\n    code === codes.dot ||\n    code === codes.colon ||\n    code === codes.semicolon ||\n    code === codes.lessThan ||\n    code === codes.questionMark ||\n    code === codes.underscore ||\n    code === codes.tilde\n  )\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction pathEnd(code) {\n  return (\n    code === codes.eof ||\n    code === codes.lessThan ||\n    markdownLineEndingOrSpace(code)\n  )\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction gfmAtext(code) {\n  return (\n    code === codes.plusSign ||\n    code === codes.dash ||\n    code === codes.dot ||\n    code === codes.underscore ||\n    asciiAlphanumeric(code)\n  )\n}\n\n/** @type {Previous} */\nfunction previousWww(code) {\n  return (\n    code === codes.eof ||\n    code === codes.leftParenthesis ||\n    code === codes.asterisk ||\n    code === codes.underscore ||\n    code === codes.tilde ||\n    markdownLineEndingOrSpace(code)\n  )\n}\n\n/** @type {Previous} */\nfunction previousHttp(code) {\n  return code === codes.eof || !asciiAlpha(code)\n}\n\n/** @type {Previous} */\nfunction previousEmail(code) {\n  return code !== codes.slash && previousHttp(code)\n}\n\n/**\n * @param {Array<Event>} events\n * @returns {boolean}\n */\nfunction previousUnbalanced(events) {\n  let index = events.length\n  let result = false\n\n  while (index--) {\n    const token = events[index][1]\n\n    if (\n      (token.type === 'labelLink' || token.type === 'labelImage') &&\n      !token._balanced\n    ) {\n      result = true\n      break\n    }\n\n    // @ts-expect-error If we’ve seen this token, and it was marked as not\n    // having any unbalanced bracket before it, we can exit.\n    if (token._gfmAutolinkLiteralWalkedInto) {\n      result = false\n      break\n    }\n  }\n\n  if (events.length > 0 && !result) {\n    // @ts-expect-error Mark the last token as “walked into” w/o finding\n    // anything.\n    events[events.length - 1][1]._gfmAutolinkLiteralWalkedInto = true\n  }\n\n  return result\n}\n"]},"metadata":{},"sourceType":"module"}